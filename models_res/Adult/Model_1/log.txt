argv: ['/home/adrien/Documents/PhD/ICLR_TTrules/ttnet/__main__.py', 'TTnet', 'Adult_run/Permutation_true_10/2022_09_06_11_21_32_506064/', '--checkpoint', '1', '--input-quantization', '0.0', '--adv-epsilon', 'min(epoch/45, 1)*0.0', '--adv-step', 'min(epoch/22,0.9)*0.0+0', '--epoch', '10', '--lr', '0.005', '--dataset', 'adult', '--type_blocks', '[TTblock]', '--last_layer', 'binpos', '--Blocks_filters_output', '[10]', '--Blocks_amplifications', '[10]', '--Blocks_strides', '[5]', '--type_first_layer_block', 'float', '--kernel_size_per_block', '[5]', '--groups_per_block', '[1]', '--padding_per_block', '[0]', '--data_augmentation', 'False', '--thr_bin_act', '[0.0,0.0]', '--thr_bin_act_test', '[0.0,0.0]', '--DATA_DIR', 'dataset/adult/', '--random_permut', 'True', '--load_permut', 'dataset/adult/adult_original_mapping.json', '--repeat_permut', '10', '--kfold', '3', '--seed', '0']
parsed args: Namespace(Blocks_amplifications=[10], Blocks_filters_output=[10], Blocks_strides=[5], DATA_DIR='dataset/adult/', act_abs_stabilize='0', act_smp_stabilize='0', adv_epsilon='min(epoch/45, 1)*0.0', adv_loss='xent', adv_steps='min(epoch/22,0.9)*0.0+0', amplifications=None, batchsize=128, bias_hinge_coeff=0, bias_hinge_thresh=0, checkpoint=1, choose_epoch=3, choose_nr_minibatch=40, data='/home/adrien/Documents/PhD/ICLR_TTrules/ttnet/data', data_augmentation='False', dataset='adult', dataset_size=10000000, epoch=10, filters=None, first_layer=None, freeze_bn='False', g_remove_last_bn=None, grad_scale_start_epoch=15, groups=None, groups_per_block=[1], groups_per_block_multihead=None, input_quantization=0.0, kernel_size_per_block=[5], kernel_size_per_block_multihead=None, kernelsizes=None, kfold=3, last_layer='binpos', load=None, load_permut='dataset/adult/adult_original_mapping.json', loss='xent', lr=0.005, net='TTnet', nr=5, output='Adult_run/Permutation_true_10/2022_09_06_11_21_32_506064/', padding_per_block=[0], paddings=None, paddings_per_block_multihead=None, preprocessing_CNN=None, random_permut=True, repeat_permut=10, seed=0, set_global_param=[], start_epoch=0, strides=None, thr_bin_act=[0.0, 0.0], thr_bin_act_test=[0.0, 0.0], type_blocks=['TTblock'], type_first_layer_block='float', verifier_mix='0', verifier_nproc=4, wait_load=False, workers=2)
global params: [('g_weight_binarizer', <class 'ttnet.modules_general.TernaryWeightWithMaskFn'>), ('g_use_scalar_scale_last_layer', True)]
network: TTnet(
  (features): Sequential(
    (0): BNs()
    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Binarize01Act()
    (3): Block_TT_1D(
      (conv1): Conv1d(1, 10, kernel_size=(5,), stride=(5,), bias=False)
      (bn1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv1d(10, 10, kernel_size=(1,), stride=(1,), bias=False)
      (bn2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act): Binarize01Act()
    )
    (4): Flatten()
    (5): BinLinearPosv2(in_features=2000, out_features=2, bias=False)
    (6): BatchNormStatsCallbak(2, scalar=True, cbd=0)
  )
)
WeightClip: 6 weight params
epoch: 0 ep.lr=0.005
[0, 0] loss=0.69/0.69 acc=78.91% tdata/train=(0.059,0.126)
[0, 20] loss=0.52/0.52 acc=71.88% tdata/train=(0.001,0.016)
[0, 40] loss=0.53/0.53 acc=75.78% tdata/train=(0.001,0.016)
[0, 60] loss=0.47/0.47 acc=75.78% tdata/train=(0.002,0.017)
[0, 80] loss=0.42/0.42 acc=80.47% tdata/train=(0.001,0.018)
[0, 100] loss=0.40/0.40 acc=82.81% tdata/train=(0.001,0.018)
[0, 120] loss=0.41/0.41 acc=81.25% tdata/train=(0.001,0.017)
[0, 140] loss=0.37/0.37 acc=82.81% tdata/train=(0.001,0.017)
[0, 160] loss=0.40/0.40 acc=82.81% tdata/train=(0.001,0.017)
[0, 180] loss=0.37/0.37 acc=81.25% tdata/train=(0.001,0.018)
[0, 200] loss=0.40/0.40 acc=84.38% tdata/train=(0.001,0.018)
sparsity@0: 76.75% ; 3070/4000.001=76.75%
test@0: acc=83.92% avg_acc=83.92% loss=0.35 pre_bn_acc=84.41%
epoch: 1 ep.lr=0.005
[1, 0] loss=0.31/0.31 acc=87.50% tdata/train=(5.377,5.411)
[1, 20] loss=0.35/0.35 acc=82.03% tdata/train=(0.002,0.020)
[1, 40] loss=0.32/0.32 acc=86.72% tdata/train=(0.001,0.018)
[1, 60] loss=0.34/0.34 acc=83.59% tdata/train=(0.001,0.016)
[1, 80] loss=0.39/0.39 acc=81.25% tdata/train=(0.001,0.019)
[1, 100] loss=0.37/0.37 acc=82.03% tdata/train=(0.001,0.020)
[1, 120] loss=0.32/0.32 acc=87.50% tdata/train=(0.002,0.023)
[1, 140] loss=0.51/0.51 acc=74.22% tdata/train=(0.002,0.026)
[1, 160] loss=0.39/0.39 acc=79.69% tdata/train=(0.002,0.025)
[1, 180] loss=0.31/0.31 acc=86.72% tdata/train=(0.002,0.024)
[1, 200] loss=0.38/0.38 acc=80.47% tdata/train=(0.001,0.022)
sparsity@1: 82.15% ; 3286/4000.001=82.15%
test@1: acc=85.00% avg_acc=84.46% loss=0.33 pre_bn_acc=84.20%
epoch: 2 ep.lr=0.005
[2, 0] loss=0.31/0.31 acc=85.16% tdata/train=(7.088,7.126)
[2, 20] loss=0.31/0.31 acc=84.38% tdata/train=(0.001,0.022)
[2, 40] loss=0.35/0.35 acc=83.59% tdata/train=(0.002,0.023)
[2, 60] loss=0.37/0.37 acc=82.03% tdata/train=(0.002,0.026)
[2, 80] loss=0.35/0.35 acc=82.81% tdata/train=(0.002,0.023)
[2, 100] loss=0.33/0.33 acc=81.25% tdata/train=(0.002,0.021)
[2, 120] loss=0.36/0.36 acc=85.94% tdata/train=(0.002,0.023)
[2, 140] loss=0.33/0.33 acc=85.16% tdata/train=(0.002,0.026)
[2, 160] loss=0.34/0.34 acc=84.38% tdata/train=(0.003,0.028)
[2, 180] loss=0.39/0.39 acc=80.47% tdata/train=(0.002,0.025)
[2, 200] loss=0.31/0.31 acc=88.28% tdata/train=(0.002,0.025)
sparsity@2: 85.38% ; 3415/4000.001=85.37%
test@2: acc=84.94% avg_acc=84.62% loss=0.33 pre_bn_acc=84.35%
epoch: 3 ep.lr=0.005
[3, 0] loss=0.38/0.38 acc=78.12% tdata/train=(8.277,8.319)
[3, 20] loss=0.38/0.38 acc=82.81% tdata/train=(0.002,0.021)
[3, 40] loss=0.31/0.31 acc=88.28% tdata/train=(0.001,0.020)
[3, 60] loss=0.36/0.36 acc=82.03% tdata/train=(0.002,0.025)
[3, 80] loss=0.42/0.42 acc=76.56% tdata/train=(0.002,0.027)
[3, 100] loss=0.43/0.43 acc=79.69% tdata/train=(0.002,0.029)
[3, 120] loss=0.25/0.25 acc=90.62% tdata/train=(0.002,0.027)
[3, 140] loss=0.28/0.28 acc=86.72% tdata/train=(0.002,0.027)
[3, 160] loss=0.34/0.34 acc=86.72% tdata/train=(0.002,0.024)
[3, 180] loss=0.30/0.30 acc=85.94% tdata/train=(0.002,0.025)
[3, 200] loss=0.30/0.30 acc=85.16% tdata/train=(0.002,0.022)
sparsity@3: 87.83% ; 3513/4000.001=87.82%
test@3: acc=85.38% avg_acc=84.81% loss=0.32 pre_bn_acc=84.84%
epoch: 4 ep.lr=0.005
[4, 0] loss=0.38/0.38 acc=81.25% tdata/train=(7.440,7.475)
[4, 20] loss=0.37/0.37 acc=81.25% tdata/train=(0.002,0.025)
[4, 40] loss=0.37/0.37 acc=83.59% tdata/train=(0.002,0.022)
[4, 60] loss=0.37/0.37 acc=80.47% tdata/train=(0.002,0.025)
[4, 80] loss=0.28/0.28 acc=89.06% tdata/train=(0.001,0.022)
[4, 100] loss=0.34/0.34 acc=87.50% tdata/train=(0.001,0.019)
[4, 120] loss=0.48/0.48 acc=76.56% tdata/train=(0.001,0.019)
[4, 140] loss=0.26/0.26 acc=89.06% tdata/train=(0.001,0.014)
[4, 160] loss=0.34/0.34 acc=79.69% tdata/train=(0.001,0.017)
[4, 180] loss=0.40/0.40 acc=78.91% tdata/train=(0.001,0.017)
[4, 200] loss=0.29/0.29 acc=86.72% tdata/train=(0.001,0.015)
sparsity@4: 89.35% ; 3574/4000.001=89.35%
test@4: acc=85.07% avg_acc=84.86% loss=0.32 pre_bn_acc=84.98%
epoch: 5 ep.lr=0.005
[5, 0] loss=0.28/0.28 acc=85.94% tdata/train=(4.686,4.712)
[5, 20] loss=0.26/0.26 acc=90.62% tdata/train=(0.001,0.017)
[5, 40] loss=0.34/0.34 acc=82.81% tdata/train=(0.001,0.018)
[5, 60] loss=0.37/0.37 acc=84.38% tdata/train=(0.001,0.018)
[5, 80] loss=0.31/0.31 acc=84.38% tdata/train=(0.001,0.018)
[5, 100] loss=0.27/0.27 acc=88.28% tdata/train=(0.002,0.021)
[5, 120] loss=0.35/0.35 acc=84.38% tdata/train=(0.001,0.016)
[5, 140] loss=0.28/0.28 acc=85.94% tdata/train=(0.001,0.018)
[5, 160] loss=0.35/0.35 acc=83.59% tdata/train=(0.001,0.016)
[5, 180] loss=0.40/0.40 acc=81.25% tdata/train=(0.001,0.017)
[5, 200] loss=0.33/0.33 acc=82.81% tdata/train=(0.001,0.020)
sparsity@5: 90.42% ; 3617/4000.001=90.42%
test@5: acc=85.27% avg_acc=84.93% loss=0.32 pre_bn_acc=85.46%
epoch: 6 ep.lr=0.005
[6, 0] loss=0.35/0.35 acc=82.03% tdata/train=(5.616,5.641)
[6, 20] loss=0.31/0.31 acc=85.94% tdata/train=(0.002,0.019)
[6, 40] loss=0.36/0.36 acc=78.91% tdata/train=(0.002,0.025)
[6, 60] loss=0.33/0.33 acc=83.59% tdata/train=(0.002,0.029)
[6, 80] loss=0.32/0.32 acc=85.94% tdata/train=(0.002,0.025)
[6, 100] loss=0.32/0.32 acc=85.94% tdata/train=(0.002,0.029)
[6, 120] loss=0.27/0.27 acc=90.62% tdata/train=(0.002,0.025)
[6, 140] loss=0.38/0.38 acc=83.59% tdata/train=(0.002,0.025)
[6, 160] loss=0.41/0.41 acc=84.38% tdata/train=(0.002,0.029)
[6, 180] loss=0.43/0.43 acc=77.34% tdata/train=(0.002,0.023)
[6, 200] loss=0.30/0.30 acc=85.94% tdata/train=(0.002,0.025)
sparsity@6: 91.22% ; 3649/4000.001=91.22%
test@6: acc=85.09% avg_acc=84.95% loss=0.32 pre_bn_acc=85.33%
epoch: 7 ep.lr=0.005
[7, 0] loss=0.34/0.34 acc=82.03% tdata/train=(7.249,7.289)
[7, 20] loss=0.37/0.37 acc=82.81% tdata/train=(0.002,0.025)
[7, 40] loss=0.38/0.38 acc=82.81% tdata/train=(0.001,0.025)
[7, 60] loss=0.37/0.37 acc=81.25% tdata/train=(0.001,0.023)
[7, 80] loss=0.25/0.25 acc=89.84% tdata/train=(0.002,0.024)
[7, 100] loss=0.33/0.33 acc=85.16% tdata/train=(0.002,0.023)
[7, 120] loss=0.24/0.24 acc=91.41% tdata/train=(0.002,0.026)
[7, 140] loss=0.27/0.27 acc=89.84% tdata/train=(0.002,0.023)
[7, 160] loss=0.31/0.31 acc=83.59% tdata/train=(0.001,0.022)
[7, 180] loss=0.28/0.28 acc=88.28% tdata/train=(0.001,0.023)
[7, 200] loss=0.32/0.32 acc=85.16% tdata/train=(0.001,0.021)
sparsity@7: 91.83% ; 3673/4000.001=91.82%
test@7: acc=85.29% avg_acc=85.00% loss=0.32 pre_bn_acc=85.49%
model choosing acc @7: 84.82%
best model update at @7
epoch: 8 ep.lr=0.005
[8, 0] loss=0.35/0.35 acc=85.94% tdata/train=(7.391,7.426)
[8, 20] loss=0.30/0.30 acc=85.16% tdata/train=(0.001,0.023)
[8, 40] loss=0.28/0.28 acc=88.28% tdata/train=(0.002,0.023)
[8, 60] loss=0.30/0.30 acc=88.28% tdata/train=(0.001,0.026)
[8, 80] loss=0.43/0.43 acc=77.34% tdata/train=(0.002,0.024)
[8, 100] loss=0.32/0.32 acc=83.59% tdata/train=(0.002,0.021)
[8, 120] loss=0.35/0.35 acc=82.81% tdata/train=(0.001,0.019)
[8, 140] loss=0.28/0.28 acc=88.28% tdata/train=(0.001,0.018)
[8, 160] loss=0.38/0.38 acc=81.25% tdata/train=(0.002,0.021)
[8, 180] loss=0.27/0.27 acc=85.16% tdata/train=(0.001,0.020)
[8, 200] loss=0.29/0.29 acc=86.72% tdata/train=(0.002,0.021)
sparsity@8: 92.47% ; 3699/4000.001=92.47%
test@8: acc=85.14% avg_acc=85.01% loss=0.32 pre_bn_acc=85.69%
model choosing acc @8: 85.10%
best model update at @8
epoch: 9 ep.lr=0.005
[9, 0] loss=0.33/0.33 acc=82.03% tdata/train=(6.832,6.867)
[9, 20] loss=0.37/0.37 acc=81.25% tdata/train=(0.002,0.021)
[9, 40] loss=0.39/0.39 acc=81.25% tdata/train=(0.002,0.021)
[9, 60] loss=0.35/0.35 acc=82.81% tdata/train=(0.003,0.030)
[9, 80] loss=0.27/0.27 acc=88.28% tdata/train=(0.002,0.023)
[9, 100] loss=0.27/0.27 acc=89.84% tdata/train=(0.002,0.021)
[9, 120] loss=0.27/0.27 acc=89.06% tdata/train=(0.001,0.021)
[9, 140] loss=0.36/0.36 acc=80.47% tdata/train=(0.002,0.019)
[9, 160] loss=0.37/0.37 acc=83.59% tdata/train=(0.002,0.023)
[9, 180] loss=0.30/0.30 acc=83.59% tdata/train=(0.001,0.021)
[9, 200] loss=0.29/0.29 acc=85.94% tdata/train=(0.001,0.017)
sparsity@9: 93.15% ; 3726/4000.001=93.15%
test@9: acc=85.21% avg_acc=85.03% loss=0.32 pre_bn_acc=85.72%
model choosing acc @9: 85.53%
best model update at @9
